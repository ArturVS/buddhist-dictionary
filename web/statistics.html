<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
  <head>
    <meta content="text/html; charset=UTF-8" http-equiv="content-type"/>
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta name="description" content="NTI Buddhist Text Reader">
    <title>NTI Buddhist Text Reader</title>
    <link rel="shortcut icon" href="images/yan.png" type="image/jpeg" />
    <link rel="stylesheet" href="//netdna.bootstrapcdn.com/bootstrap/3.0.3/css/bootstrap.min.css">
    <!-- Custom styles for this template -->
    <link rel="stylesheet" href="buddhistdict.css" rel="stylesheet">
    <!-- HTML5 shim and Respond.js IE8 support of HTML5 elements and media queries -->
    <!--[if lt IE 9]>
      <script src="https://oss.maxcdn.com/libs/html5shiv/3.7.0/html5shiv.js"></script>
      <script src="https://oss.maxcdn.com/libs/respond.js/1.3.0/respond.min.js"></script>
    <![endif]-->
  </head>
  <body>
    <div class="starter-template">
      <div class="row">
        <div class="span2"><img id="logo" src="images/yan.png" alt="Logo" class="pull-left"/></div>
        <div class="span7"><h1>NTI Buddhist Text Reader</h1></div>
      </div>
    </div>
    <div class="navbar navbar-inverse navbar-fixed-top" role="navigation">
      <div class="container">
        <div class="navbar-header">
          <button type="button" class="navbar-toggle" data-toggle="collapse" data-target=".navbar-collapse">
            <span class="sr-only">Toggle navigation</span>
            <span class="icon-bar"></span>
            <span class="icon-bar"></span>
            <span class="icon-bar"></span>
          </button>
          <a class="navbar-brand" href="index.html">Home</a>
        </div>
        <div class="collapse navbar-collapse">
          <ul class="nav navbar-nav">
            <li><a href="corpus.html">Texts</a></li>
            <li class="active"><a href="tools.html">Tools</a></li>
            <li><a href="dict_resources.html">Resources</a></li>
            <li><a href="about.html">About</a></li>
          </ul>
        </div><!--/.nav-collapse -->
      </div>
    </div>

    <div class="container">
      <h2>Statistical Methods</h2>
      <p>
        This page gives some incomplete notes on statistical methods in analyzing Chinese text 
        to solve text analysis, historical linguistcs, and content analysis problems.
      </p>
      <h3>Probability</h2>
      <p>
        The <strong>conditional probability</strong> of an event A given that we know an event B has already occured is written Pr(A|B).
        It can be computed as 
      </p>
      <p class='formula'>
        Pr(A|B) = Pr(A ∩ B) / Pr(B)
      </p>
      <p>
        This assumes that Pr(B) > 0. (DeGroot and Morris, <i>Probability and Statistics</i>, 56)
      </p>
      <p>
        <strong>Example</strong>: Suppose that we wish to find the probability finding the character 說 at a particular position in the text. 
        In modern Chinese, the sequence 我說 is very common.
        So, if we know the previous character is 我 then the probability may be higher than the probability of finding the character 說
        alone. That is, Pr(A=說|B=我) > Pr(A=說).
      </p>
      <p>
        A <strong>stochastic process</strong> is a sequence of random variables X<sub>1</sub>, X<sub>2</sub>, ... at discrete points
        in time. A <strong>Markov chain</strong> is a stochastic process where the conditional distributions of all X<sub>n+j</sub>
        depend only on X<sub>n</sub> and not only earlier states.
        (DeGroot and Morris, <i>Probability and Statistics</i>, 188)
      </p>
      <p>
        The <strong>transition distributions</strong> of a Markov chain are the conditional probabilities 
      </p>
      <p class='formula'>
        p<sub>ij</sub> = Pr(X<sub>n+1</sub>=j|X<sub>n</sub>=i)
      </p>
      <p>
        where the random variables X<sub>n</sub> can have k possible states.
        A <strong>transition matrix</strong> is a matrix <strong>P</strong> = [p<sub>ij</sub>] made up of the conditional probabilities of the 
        transition distributions.
        (DeGroot and Morris, <i>Probability and Statistics</i>, 190-192)
      </p>
      <p>
        <strong>Example</strong>: A stream of words can be thought of as a Markov chain. The earlier words can influence the later
        words. In a simple statistical model, each word may only be influenced by the preceding words. 
      </p>
      <h3>Expectation</h2>
      <p>
        The <strong>expectation</strong> of a discrete random variable X with probability function f is defined as 
      </p>
      <p class='formula'>
        E(X) = Σ<sub>All x</sub> xf(x)
      </p>
      <p>
        (DeGroot and Morris, <i>Probability and Statistics</i>, 208)
      </p>
      <p>
        The <strong>variance</strong> of a discrete random variable X with mean μ is defined as
      </p>
      <p class='formula'>
        Var(X) = E[(X - μ)<sup>2</sup>]
      </p>
      <p>
        The <strong>standard deviation</strong> is the square root of the variance.
        (DeGroot and Morris, <i>Probability and Statistics</i>, 226)
      </p>
      <p>
        The <strong>covariance</strong> of random variables X and Y with means μ<sub>x</sub> and μ<sub>y</sub> 
        is defined as
      </p>
      <p class='formula'>
        Cov(X, Y) = E[(X - μ<sub>x</sub>)(Y - μ<sub>y</sub>)]
      </p>
      <p>
        assuming that the expectation exists.
        (DeGroot and Morris, <i>Probability and Statistics</i>, 248)
      </p>
      <p>
        The <strong>correlation</strong> of random variables X and Y with variances σ<sub>x</sub><sup>2</sup> and 
        σ<sub>y</sub><sup>2</sup> is defined as
      </p>
      <p class='formula'>
        ρ(X, Y) = Cov(X, Y) / [σ<sub>x</sub>σ<sub>y</sub>]
      </p>
      <p>
        (DeGroot and Morris, <i>Probability and Statistics</i>, 250)
      </p>
      <h3>Special Distributions</h2>
      <p>
        The <strong>Bernoulli distribution</strong> for random variable X, which can only take the values 0 and 1,
        with parameter p (0 ≤ p ≤ 1) has the probabilities
      </p>
      <p class='formula'>
        Pr(X = 1) = p and Pr(X = 0) = 1 - p
      </p>
      <p>
        An sequence random variables with the Bernoulli distribution are called <strong>Bernoulli trials</strong>.
        (DeGroot and Morris, <i>Probability and Statistics</i>, 276)
      </p>
      <p>
        The <strong>Binomial distribution</strong> with integer parameter n and continuous parameter p (0 ≤ p ≤ 1)
        is defined as 
      </p>
      <p class='formula'>
         f(x|n,p) = (n ¦ x) p<sup>x</sup>(1 - p)<sup>n-x</sup> for x = 0, 1, 2, ... and 0 otherwise
      </p>
      <p>
        where (n ¦ x) is the binomial coefficient n!/[x!(n - x)].
        The mean and variance are
      </p>
      <p class='formula'>
         E(X) = np
      </p>
      <p class='formula'>
         Var(X) = np(1 - p)
      </p>
      <p>
        (DeGroot and Morris, <i>Probability and Statistics</i>, 277)
      </p>
      <p>
        The <strong>Poisson distribution</strong> for random variable X with mean λ is defined as
      </p>
      <p class='formula'>
         f(x|λ) = e<sup>-λ</sup> λ<sup>x</sup>/x! for x = 0, 1, 2, ... and 0 otherwise.
      </p>
      <p>
        The variance of the Poisson distribution is also λ.
        (DeGroot and Morris, <i>Probability and Statistics</i>, 288-290)
      </p>
      <p>
        The <strong>normal distribution</strong> for the continuous random variable X with mean μ and 
        standard deviation σ is defined as
      </p>
      <p class='formula'>
         f(x|μ, σ) = [1/σ√(2π)] exp[-0.5((x - μ)/σ)<sup>2</sup>] for -∞ &lt; x &lt; ∞
      </p>
      <p>
        The normal distribution is a good approximation for variables in many random processes.
        (DeGroot and Morris, <i>Probability and Statistics</i>, 303)
        The <strong>Central Limit Theorem</strong> states that the distribution of a sum of 
        random variables Σ<sub>i=1</sub><sup>n</sup> X<sub>i</sub>  with any distribution will be
        approximately the normal distribition with mean nμ and variance nσ<sup>2</sup>, as
        n becomes large.
      </p>
      <p>
        The <strong>multinomial distribution</strong> for the discrete random vector 
        <strong>X</strong> = (X<sub>1</sub>, X<sub>2</sub>, ... X<sub>k</sub>) having probabilities
        <strong>p</strong> = (p<sub>1</sub>, p<sub>2</sub>, ... p<sub>k</sub>) 
        with n items selected is defined as
      </p>
      <p class='formula'>
         f(<strong>X</strong>|n, <strong>p</strong>) = [n!/(x<sub>1</sub> x<sub>2</sub> ... x<sub>k</sub>)]
         p<sub>1</sub><sup>x<sub>1</sub></sup> p<sub>2</sub><sup>x<sub>2</sub></sup> ... p<sub>k</sub><sup>x<sub>k</sub></sup>
      </p>
      <p>
        if x<sub>1</sub> + x<sub>2</sub> + ... x<sub>k</sub> = n or 0 otherwise.
        The multinomial distribution is appropriate for distributions into sets that are not necessarily numbers,
        for example, the frequencies of words of different part of speech values.
        (DeGroot and Morris, <i>Probability and Statistics</i>, 334)
      </p>
      <h3>References</h3>
      <ol>
        <li>
          DeGroot, Morris H., and Mark J. Schervish. <i>Probability and Statistics</i>. 4 edition. Boston: Pearson, 2011.
        </li>
      <hr/>
      <p>
        Copyright Nan Tien Institute 2013 - 2014, 
        <a href="http://www.nantien.edu.au/" title="Fo Guang Shan Nan Tien Institute">www.nantien.edu.au</a>.
      </p>
      <p>This page was last updated on November 8, 2014.</p>
     </div>
    <script src="https://code.jquery.com/jquery-1.10.2.min.js"></script>
    <script src="//netdna.bootstrapcdn.com/bootstrap/3.0.3/js/bootstrap.min.js"></script>
  </body>
</<html>
