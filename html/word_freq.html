<h2>Introduction to Corpus Analysis of the Chinese Buddhist Canon</h2>
<h3>Page Contents</h3>
<ul>
  <li><a href="#ntireader">The NTI Reader Corpus</a></li>
  <li><a href="#whatis">What is Corpus Analysis?</a></li>
  <li><a href="#word_freq">Word Frequency analysis</a></li>
  <li><a href="#content">Content Analysis</a></li>
  <li><a href="#usage">Word Usage Analysis</a></li>
  <li><a href="#collocation">Collocation Analysis</a></li>
  <li><a href="#extraction">Terminology Extraction</a></li>
  <li><a href="#related">Related</a></li>
  <li><a href="#references">References</a></li>
</ul>
<p>
  This page explains some of the linguistic details of the corpus analysis
  of the Chinese Buddhist Canon included in the NTI Reader. The page
  may be useful to people wanting to do terminology extraction of those
  with an interest in computational linguistics. The page <a 
  href='annotation.html'>Description of the NTI Reader</a> gives more
  details on the elements and construction of the NTI Reader.
</p>
<h3 id='ntireader'>The NTI Reader Corpus</h3>
<p>
  The NTI Reader is built on text in volumes 1-55 of the <a
  href='taisho/taisho.html'>Taishō shinshū daizōkyō</a> 《大正新脩大藏經》
  (Taishō) version of the Chinese Buddhist canon as a monolingual historic
  corpus. This is in contrast with a bilingual parallel corpus that
  matches two languages together in that the entire body of the corpus
  is literary Chinese. However, the metadata describing the corpus is in
  English to help users navigate the collection of texts.
</p>
<p>
  As explained in the page <a href='annotation.html'>Description of the
  NTI Reader</a> the <a
  href="https://github.com/alexamies/chinesenotes.com/tree/master/go/src/cnreader"
  title="Command line tool on GitHub">cnreader</a> tool analyzes the 
  Taishō version of the Chinese Buddhist canon. In
  addition to generating text files for the text reader, the program
  analyses the collection of texts as a corpus to find word frequencies,
  bigram frequencies, collocations, and extract example uses for words 
  in the NTI Reader dictionary. The analysis results for the entire
  set of texts is shown in the page 
  <a href='analysis/corpus_analysis.html'>Corpus Analysis</a>.
</p>
<p>
  Source texts are marked with genre to allow analysis to be broken by
  genre. Example genres are āgama, jātaka, and prajñāpāramitā. The most
  interesting aspect of this is to allow identification of keywords for
  specific genres. The genres are taken from the section titles of the
  Taishō.
</p>
<h3 id='whatis'>What is Corpus Analysis?</h3>
<p>
  The <i>Routledge Dictionary of Language and Linguistics</i> defines a corpus
  as “A finite set of concrete linguistic utterances that serves as an empirical
  basis for linguistic research” (Bussmann, s.v. 'corpus'). One of the uses of a
  corpus is that it gives way to see how a word is used in many different
  contexts. This can help in confirming the correctness of word senses in a
  dictionary and be a source of examples. Modern corpora, such as the British
  National Corpus, are taken from a variety of sources, such as newspapers,
  books and web pages that are mostly intended for linguistic research rather
  than to be read for the value of the content. For example, corpora may be used
  to compile lists of commonly occurring multiword expressions and keywords for
  compilation of translation glossaries.
</p>
<p>
  Corpora may be distinguished as monolingual, bilingual and multilingual
  varieties (McEnery and Hardie 2011, loc. 756-815). Examples, characteristics
  and primary uses of different kinds of corpora are summarized in Table 1.
</p>
<table>
  <caption>Table 2: Example corpora and uses</caption>
  <tbody>
    <tr>
      <th>&nbsp;</th>
      <th>Historic</th>
      <th>Modern</th>
      <th>Main Characteristics</th>
      <th>Main uses</th>
    </tr>
    <tr>
      <th>Monolingual</th>
      <td>
        Helsinki Corpus of English Texts, ARCHER (A Representative Corpus of
        Historic English Registers), Corpus of Early English Correspondence,
        NTI Reader
      </td>
      <td>
        Brown Corpus, British National Corpus, Lancaster Corpus of Mandarin
        Chinese, Enron Corpus (emails)
      </td>
      <td>
        Large volume
      </td>
      <td>
        Linguistic study, lexicography, inference
      </td>
    </tr>
    <tr>
      <th>Bilingual</th>
      <td>BDK-SAT parallel corpus</td>
      <td>English-Norwegian Parallel Corpus</td>
      <td>Aligned</td>
      <td>Translation, lexicography</td>
    </tr>
    <tr>
      <th>Multilingual</th>
      <td>
        Universal Dependencies (ancient Greek, Gothic, Latin, and Old Church
        Slavonic)
      </td>
      <td>Universal Dependencies (36 modern languages)</td>
      <td>POS tagged and parsed, not aligned</td>
      <td>Training for automated translation</td>
    </tr>
  </tbody>
</table>
<h3 id='word_freq'>Word Frequency analysis</h3>
<p>
  Word frequency analysis is useful in getting an idea of an untranslated text.
  This is important because there is more untranslated text than translated text
  in the Chinese Buddhist canon and other Chinese text collections.  
  Even for translated texts a word frequency
  analysis can be useful for writing a commentary or doing a close reading.
  It can also be useful for comparing different translations for style and quality or
  for comparing different historic recensions of the same source document.
</p>
<p>
  A frequency distribution of non-functional words can give an idea of the content 
  of a text at a quick glance. A frequency distribution of functional words can 
  give an idea of the style of a translator, the histoic period written, and the 
  translation source (e.g.,Sanskrit). A frequency distribution of proper nouns 
  (not implemented yet) can give an idea of the principal actors in a text.
  A character frequency distribution may be more useful when your are missing 
  vocabulary.
</p>
<p>
  You need a good base vocabulary to do a word frequency analysis in Chinese.
  Since Chinese text does not have spaces in between words you need the vocabulary
  to find the boundaries between the words. Otherwise, you will simply end of with
  a character frequency distribution. The NTI Reader dictionary is 
  essential for the word frequency analysis.
</p>
<p>
  A word frequency analysis by genre is also done. This uses genre labels
  for texts according to their position in the Taishō. For example,
  Āgama for volumes 1-2, Jātaka and Avadāna for volumes 3-4, and
  Prajñāpāramitā for volumes 5-8.
</p>
<h3 id='content'>Content Analysis</h3>
<p>
  Word frequency analysis is also done for each individual text. Analysis
  of individual texts it is referred to <em>content analysis</em> rather
  than corpus analysis, which refers to the entire set of texts.
  For example, see the content analysis results for the 
  <a href='analysis/taisho/t1666_analysis.html'>Treatise on the Awakening
  of Faith in the Mahāyāna</a> (T 1666).
</p>
<h3 id='usage'>Word Usage Analysis</h3>
<p>
  In addition to an overall analysis of whole corpus and each text within
  it, the analysis results can be view for each word. This includes the
  texts that the word is mentioned most frequently in, collocations, and
  examples of word usage. The list of texts that the word is mentioned
  most frequently in provides links to specific locations within the 
  Buddhist text that use the given word most frequently.
  For example, looking at the page for the word 真如 zhēnrú tathatā or 
  'suchness' we find that the term is most frequently mentioned in 
  Scroll 16 of the the Large Sūtra on Perfection of Wisdom (T 220).
</p>
<h4 id='collocation'>Collocation Analysis</h4>
<p>
  A <em>collocation</em> is a habitual combination of words
  (Crystal 2008, s.v. 'collocation'). For example, in English, an
  <i>auspicious occasion</i> or <i>draw a conclusion</i>.
  Some collocations express sentiment. For example, the collocations
  a <i>notorious thief</i> and <i>habitual gambler</i> express negative
  sentiments. This is related to the concept of <i>semantic prosody</i>,
  which describes words that occur together with other words in a 
  semantic set (Crystal 2008, s.v. 'semantic prosody').
  Collocations are important in translation and will usually be 
  translation units.
</p>
<p>
  List of collocations in the NTI Reader are based on a bigram analysis
  of the corpus. To avoid the list being dominated by common bigrams that
  are related to free selection with function words, bigrams with 
  function words are removed from the set.
</p>
<h3 id='extraction'>Terminology Extraction</h3>
<p>
  Other words were found in reading Buddhist texts or examining the 
  bigram frequency list and then added the dictionary after
  checking the defintions in one or more of the <a href='references.html'
  >References</a>.
  In addition, Corpus analysis has also be used to identify words
  subsequently added to the NTI Reader dictionary. 
</p>
<p>
  The scan of the texts by the cnreader
  software identifies all the Chinese characters that are not in the
  dictionary. Word entries for these characters are then added using
  the Jupyter notebook <a
  href='https://github.com/alexamies/chinesenotes.com/blob/master/python/unihan.ipynb'
  >unihan.ipynb</a> from the entry in the Unihan database
  (Unicode Consortium 2016, 'Unihan Database Lookup').
</p>
<p>
  Titles for texts in the Taishō were extracted from 
  <a href='http://cbeta.org/'>CBETA</a>, which is shared under Creative
  Commons, and the The Korean Buddhist Canon: A Descriptive Catalogue
  (Lancaster, 2004), which was used with permission. This was automated
  using the <a 
  href='https://github.com/alexamies/chinesenotes.com/blob/master/python/add_title.ipynb'
  >add_title.ipynb</a> Jupyter notebook.
</p>
<p>
  Bigrams were identified, ranked by frequency of occurance, and
  compared against head words in the Ding Fubao's 《丁福保佛學大辭典》
  ‘Dictionary of Buddhist Studies’ (Ding, 2010). In the latest run there
  were 9,980 words identified with this method. This can be run from
  the Jupyter notebook <a
  href="https://github.com/alexamies/buddhist-dictionary/blob/master/python/term_extraction.ipynb"
  >term_extraction.ipynb</a>.
</p>
<h3 id='related'>Related</h3>
<p>
  For more (slightly older) on word frequency analysis see the page 
  <a href="statistics.html">Statistical Background</a>.
</p>
<h3 id='references'>References</h3>
<p>
  <ol>
    <li>
      Bussmann H, Trauth G (trans.), Kazzazi K (trans.) 2006, <i>Routledge
      Dictionary of Language and Linguistics</i>, Routledge, London.
    </li>
    <li>
      Crystal, D 2008, <i>Dictionary of Linguistics and Phonetics</i>,
      6th edition (Kindle), Wiley-Blackwell, Malden, MA ; Oxford.
    </li>
    <li>
      Lancaster, LR 2004, <i>The Korean Buddhist Canon: A Descriptive
      Catalogue</i>, accessed 11 February 2017, 
      <a href='http://www.acmuller.net/descriptive_catalogue/'
      >http://www.acmuller.net/descriptive_catalogue/</a>.
    </li>
    <li>
      McEnery, T and Hardie, A 2011, <i>Corpus Linguistics: Method, Theory and
      Practice</i>. Cambridge University Press.
    </li>
    <li>
      Unicode Consortium 2016, 'Unihan Unicode Database', accessed 
      11 February 2017, <a href='http://www.unicode.org/reports/tr38/'
      >http://www.unicode.org/reports/tr38/</a>.
    </li>
  </ol>
</p>
